{
  "name": "Qwen Image",
  "description": "Workflow for Qwen Image UNET model",
  "defaults": {
    "width": 1024,
    "height": 1024,
    "steps": 20,
    "cfg": 2.5,
    "sampler_name": "euler",
    "scheduler": "simple"
  },
  "groups": [
    {
      "id": 1,
      "title": "Diffusion Model",
      "member_nodes": ["1", "note:1"]
    },
    {
      "id": 2,
      "title": "CLIP Configuration",
      "member_nodes": ["2", "note:2"]
    },
    {
      "id": 3,
      "title": "VAE Configuration",
      "member_nodes": ["3", "note:3"]
    },
    {
      "id": 4,
      "title": "Sampling Configuration",
      "member_nodes": ["8", "note:4"]
    }
  ],
  "notes": [
    {
      "id": 1,
      "title": "Diffusion Model Selection",
      "content": "### Recommended UNET Model\n\nUse **Qwen Image FP8 e4m3fn** for optimal results."
    },
    {
      "id": 2,
      "title": "CLIP Model Selection",
      "content": "### Recommended CLIP Model\n\nUse **2.5 VL 7B FP8 Scaled** for optimal text understanding with Qwen Image."
    },
    {
      "id": 3,
      "title": "VAE Selection",
      "content": "### Recommended VAE\n\nUse **Qwen Image** VAE for optimal results with Qwen Image models."
    },
    {
      "id": 4,
      "title": "Sampler Settings",
      "content": "### Recommended Settings\n\n- **Steps:** 20\n- **CFG:** 2.5\n- **Sampler:** euler\n- **Scheduler:** simple"
    }
  ],
  "nodes": {
    "1": {
      "class_type": "UNETLoader",
      "inputs": {
        "unet_name": "{{unet_name}}",
        "weight_dtype": "default"
      },
      "_meta": {
        "title": "Load Diffusion Model"
      }
    },
    "2": {
      "class_type": "CLIPLoader",
      "inputs": {
        "clip_name": "{{clip_name}}",
        "type": "qwen_image",
        "device": "default"
      },
      "_meta": {
        "title": "Load CLIP"
      }
    },
    "3": {
      "class_type": "VAELoader",
      "inputs": {
        "vae_name": "{{vae_name}}"
      },
      "_meta": {
        "title": "Load VAE"
      }
    },
    "4": {
      "class_type": "EmptySD3LatentImage",
      "inputs": {
        "width": "{{width}}",
        "height": "{{height}}",
        "batch_size": "{{batch_size}}"
      },
      "_meta": {
        "title": "Empty Latent Image"
      }
    },
    "5": {
      "class_type": "CLIPTextEncode",
      "inputs": {
        "text": "{{positive_prompt}}",
        "clip": ["2", 0]
      },
      "_meta": {
        "title": "CLIP Text Encode (Positive Prompt)"
      }
    },
    "6": {
      "class_type": "CLIPTextEncode",
      "inputs": {
        "text": "{{negative_prompt}}",
        "clip": ["2", 0]
      },
      "_meta": {
        "title": "CLIP Text Encode (Negative Prompt)"
      }
    },
    "7": {
      "class_type": "ModelSamplingAuraFlow",
      "inputs": {
        "shift": 3.1,
        "model": ["1", 0]
      },
      "_meta": {
        "title": "ModelSamplingAuraFlow"
      }
    },
    "8": {
      "class_type": "KSampler",
      "inputs": {
        "seed": "{{seed}}",
        "steps": "{{steps}}",
        "cfg": "{{cfg}}",
        "sampler_name": "{{sampler_name}}",
        "scheduler": "{{scheduler}}",
        "denoise": 1.0,
        "model": ["7", 0],
        "positive": ["5", 0],
        "negative": ["6", 0],
        "latent_image": ["4", 0]
      },
      "_meta": {
        "title": "KSampler"
      }
    },
    "9": {
      "class_type": "VAEDecode",
      "inputs": {
        "samples": ["8", 0],
        "vae": ["3", 0]
      },
      "_meta": {
        "title": "VAE Decode"
      }
    },
    "10": {
      "class_type": "SaveImage",
      "inputs": {
        "filename_prefix": "ComfyChair",
        "images": ["9", 0]
      },
      "_meta": {
        "title": "Save Image"
      }
    }
  }
}
